# Copyright (C) 2005-2021 Splunk Inc. All Rights Reserved.
[ontap:perf]
KV_MODE = multi_tsv

[source::SystemPerfHandler]
FIELDALIAS-cpu_load_percent = cpu_busy_percent as cpu_load_percent
FIELDALIAS-read_ops = read_ops_rate as read_ops
FIELDALIAS-write_ops = write_ops_rate as write_ops
FIELDALIAS-io_ops = total_ops_rate as io_ops
FIELDALIAS-storage_read_throughput = disk_data_read_rate as  storage_read_throughput
FIELDALIAS-storage_write_throughput = disk_data_written_rate as  storage_write_throughput
FIELDALIAS-network_usage_in = net_data_recv_rate as network_usage_in
FIELDALIAS-network_usage_out = net_data_sent_rate as network_usage_out
FIELDALIAS-latency = sys_avg_latency_average as latency, total_latency_average as latency
EVAL-array_id = if('instance_uuid'=="None", 'system_id', 'array_id') 
EVAL-read_latency = coalesce(read_latency_average, sys_read_latency_average)
EVAL-write_latency = coalesce(write_latency_average, sys_write_latency_average)
EVAL-dest = host+":"+objname

[source::AggrPerfHandler]
EVAL-pool_id = case(instance_uuid == 'node_name'.":kernel:".'instance_name', 'node_uuid'.":".'instance_name', 'instance_uuid'!= "None", 'instance_uuid')
FIELDALIAS-io_ops = total_transfers_rate as io_ops 

[source::VolumePerfHandler]
FIELDALIAS-read_ops = read_ops_rate as read_ops
FIELDALIAS-write_ops = write_ops_rate as write_ops
FIELDALIAS-volume_id = instance_uuid as volume_id
FIELDALIAS-io_ops = total_ops_rate as io_ops
EVAL-storage_read_throughput = read_data_rate / 1024
EVAL-storage_write_throughput = write_data_rate / 1024
EVAL-dest = host+":"+objname
EVAL-read_latency = read_latency_average/1000
EVAL-write_latency = write_latency_average/1000
EVAL-latency = avg_latency_average/1000

[source::LunPerfHandler]
FIELDALIAS-lun_id = objuuid as lun_id
FIELDALIAS-io_ops = total_ops_rate as io_ops
EVAL-storage_read_throughput = read_data_rate / 1024
EVAL-storage_write_throughput = write_data_rate / 1024
FIELDALIAS-read_ops = read_ops_rate as read_ops
FIELDALIAS-write_ops = write_ops_rate as write_ops
FIELDALIAS-latency = avg_latency_average as latency
FIELDALIAS-read_latency  = avg_read_latency_average as read_latency
FIELDALIAS-write_latency  = avg_write_latency_average as write_latency

[source::DiskPerfHandler]
#Per the documentaiton, disk_capacity is MB
FIELDALIAS-storage = disk_capacity as storage
EVAL-dest = host+":"+objname
FIELDALIAS-read_blocks = user_read_blocks_rate as read_blocks
FIELDALIAS-disk_id = instance_uuid as disk_id
FIELDALIAS-io_ops = total_transfers_rate as io_ops
FIELDALIAS-read_ops = read_ops_rate as read_ops, user_reads_rate as read_ops
FIELDALIAS-write_ops = write_ops_rate as write_ops, user_writes_rate as write_ops
FIELDALIAS-write_blocks = user_write_blocks_rate as write_blocks
EVAL-storage_read_throughput = read_data_rate / 1024
EVAL-storage_write_throughput = write_data_rate / 1024
EVAL-read_latency = user_read_latency_average/1000
EVAL-write_latency = user_write_latency_average/1000
EVAL-latency = max(tonumber(user_read_latency_average), tonumber(user_write_latency_average))/1000

[ontap:volume]
#tag performance storage
FIELDALIAS-storage = size-total as storage
FIELDALIAS-storage_used = size-used as storage_used
FIELDALIAS-storage_used_percent = percentage-used as storage_used_percent 
FIELDALIAS-fd_max = files-total as fd_max
FIELDALIAS-fd_used = files-used as fd_used
FIELDALIAS-fd_max2 = volume-inode-attributes.files-total as fd_max
FIELDALIAS-fd_used2 = volume-inode-attributes.files-used as fd_used
#Storage
FIELDALIAS-storage_used_percent2 = volume-space-attributes.percentage-size-used as storage_used_percent
FIELDALIAS-storage_used2 = volume-space-attributes.size-used as storage_used
#Volume storage information is in bytes, change to MB
EVAL-storage = storage/(1024*1024)
EVAL-storage_used = storage_used/(1024*1024)
FIELDALIAS-volume_id = instance-uuid as volume_id, volume-id-attributes.instance-uuid as volume_id
FIELDALIAS-pool_name = volume-id-attributes.containing-aggregate-name as pool_name, containing-aggregate as pool_name
FIELDALIAS-pool_id = volume-id-attributes.containing-aggregate-uuid as pool_id
FIELDALIAS-storage_capacity = volume-space-attributes.size as storage_capacity, size-total as storage_capacity
FIELDALIAS-storage_free = volume-space-attributes.size-available as storage_free, size-available as storage_free
EVAL-volume_name = case(source=="volume-get-iter", 'volume-id-attributes.name', source == "volume-list-info-iter-start", 'name')

[ontap:aggr]
FIELDALIAS-pool_id = uuid as pool_id
FIELDALIAS-pool_name = name as pool_name, aggregate-name as pool_name
FIELDALIAS-storage_capacity = aggr-space-attributes.size-total as storage_capacity, size-total as storage_capacity
FIELDALIAS-storage_used = aggr-space-attributes.size-used as storage_used , size-used as storage_used
FIELDALIAS-storage_free = aggr-space-attributes.size-available as storage_free, size-available as storage_free
EVAL-storage_used_percent = case(source=="aggr-get-iter", ('aggr-space-attributes.size-used'*100)/'aggr-space-attributes.size-total', source=="aggr-list-info", ('size-used'*100)/ 'size-total')

[ontap:disk]
FIELDALIAS-disk_id = disk-inventory-info.disk-uid as disk_id, disk-uid as disk_id 
FIELDALIAS-disk_name = disk-name as disk_name, name as disk_name
FIELDALIAS-disk_type = disk-inventory-info.disk-type as disk_type, disk-type as disk_type 
FIELDALIAS-vendor_product = disk-inventory-info.model as vendor_product, disk-model as vendor_product
FIELDALIAS-raid_group = disk-raid-info.disk-aggregate-info.raid-group-name as raid_group, raid-group as raid_group
FIELDALIAS-pool_name = 	disk-raid-info.disk-aggregate-info.aggregate-name as pool_name, aggregate as pool_name
EVAL-storage_capacity = case(source== "storage-disk-get-iter", 'disk-inventory-info.bytes-per-sector' * 'disk-inventory-info.capacity-sectors',  source=="disk-list-info", 'physical-space')
EVAL-vendor = case(source=="storage-disk-get-iter", 'disk-inventory-info.vendor', source=="disk-list-info", trim('vendor-id'))

[ontap:system]
FIELDALIAS-cpu_count = number-of-processors as cpu_count
FIELDALIAS-cpu_mhz = cpu-processor-type as cpu_mhz
FIELDALIAS-mem = memory-size as mem
FIELDALIAS-os = version as os, product-version as os
FIELDALIAS-vendor = vendor-id as vendor
FIELDALIAS-dest = system-name as dest
FIELDALIAS-serial = system-serial-number as serial
FIELDALIAS-version = system-model as version
FIELDALIAS-product = system-serial-number as product 
FIELDALIAS-vendor_product = system-model as vendor_product
EVAL-controller_mode = case('source'=="system-get-info", "7-mode", 'source'=="system-get-node-info-iter", "cluster-mode")
FIELDALIAS-array_id = node-uuid as array_id
FIELDALIAS-array_name = system-name as array_name
FIELDALIAS-logical_cpu_count = number-of-processors as logical_cpu_count
EVAL-mem_capacity = 'memory-size' * 1024 * 1024

[source::system-get-info]
FIELDALIAS-array_id = system-id as array_id


[ontap:lun]
FIELDALIAS-lun_path = path as lun_path
FIELDALIAS-serial_number = serial-number as serial
FIELDALIAS-accessible = online as accessible
FIELDALIAS-storage_capacity = size as storage_capacity
EXTRACT-volume_name =  path.*?\/vol\/(?<volume_name>.*?)\/
EXTRACT-lun_name =  path":\s"[\w\-\_\/]+\/(?<lun_name>.*?)\"\,
EVAL-lun_id = case(source=="lun-list-info", 'path'."-".'serial-number', source=="lun-get-iter", 'uuid')
EVAL-storage_free = size-'size-used'

[source::.../var/log/splunk/hydra_scheduler*]
LINE_BREAKER = ([\r\n]+)\d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
BREAK_ONLY_BEFORE = \d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
SHOULD_LINEMERGE = false
REPORT-schedulerfields = hydra_scheduler_log_fields
sourcetype = hydra_scheduler

[source::.../var/log/splunk/hydra_worker*]
LINE_BREAKER = ([\r\n]+)\d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
BREAK_ONLY_BEFORE = \d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
SHOULD_LINEMERGE = false
REPORT-workerfields = hydra_worker_log_fields
sourcetype = hydra_worker

[source::.../var/log/splunk/hydra_gateway*]
LINE_BREAKER = ([\r\n]+)\d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
BREAK_ONLY_BEFORE = \d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
SHOULD_LINEMERGE = false
REPORT-gatewayfields = hydra_gateway_log_fields
sourcetype = hydra_gateway

[source::.../var/log/splunk/hydra_gatekeeper*]
LINE_BREAKER = ([\r\n]+)\d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
BREAK_ONLY_BEFORE = \d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
SHOULD_LINEMERGE = false
sourcetype = hydra_gatekeeper

[source::.../var/log/splunk/hydra_access*]
LINE_BREAKER = ([\r\n]+)\d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
BREAK_ONLY_BEFORE = \d\d\d\d-\d\d-\d\d\s\d\d:\d\d:\d\d
SHOULD_LINEMERGE = false
REPORT-gatewayfields = hydra_access_log_fields
sourcetype = hydra_access